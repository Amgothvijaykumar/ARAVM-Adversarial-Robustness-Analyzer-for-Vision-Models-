"""
Complete Captum Insights setup with Pre-trained ResNet
Works in Jupyter Notebook with interactive widgets
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torchvision import models, transforms
from PIL import Image
import numpy as np
import os

from captum.insights import AttributionVisualizer, Batch
from captum.insights.attr_vis.features import ImageFeature

# ============================================
# STEP 1: Load Pre-trained ResNet Model
# ============================================

def get_pretrained_resnet():
    """Load pre-trained ResNet50 model"""
    model = models.resnet50(pretrained=True)
    model.eval()
    return model

# ============================================
# STEP 2: Define Class Labels (ImageNet)
# ============================================

def get_imagenet_classes():
    """
    Get ImageNet class labels
    Returns first 1000 classes for ImageNet classification
    """
    # Download class labels
    import urllib
    url = "https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
    
    try:
        with urllib.request.urlopen(url) as f:
            classes = [line.decode('utf-8').strip() for line in f.readlines()]
        return classes
    except:
        # Fallback: return generic labels
        return [f"Class_{i}" for i in range(1000)]

# ============================================
# STEP 3: Define Baseline Function
# ============================================

def baseline_func(input_tensor):
    """
    Baseline function for attribution
    Returns a black image (zeros)
    """
    return input_tensor * 0

# Alternative baselines:
def baseline_func_mean(input_tensor):
    """Baseline: mean of the image"""
    return torch.ones_like(input_tensor) * input_tensor.mean()

def baseline_func_blur(input_tensor):
    """Baseline: blurred version of image"""
    from torchvision.transforms import functional as TF
    return TF.gaussian_blur(input_tensor, kernel_size=[11, 11])

# ============================================
# STEP 4: Create Dataset Iterator
# ============================================

def formatted_data_iter():
    """
    Create a data iterator for Captum Insights
    
    This can load images from:
    - A folder of images
    - A dataset (e.g., ImageNet, CIFAR)
    - Individual image files
    
    Yields Batch objects with inputs and labels
    """
    
    # Option 1: Load from folder of images
    image_folder = "sample_images"  # Your image folder
    
    # Create transform to tensor (no normalization yet)
    transform = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor()
    ])
    
    # Check if folder exists
    if os.path.exists(image_folder):
        from glob import glob
        image_files = glob(os.path.join(image_folder, "*.jpg")) + \
                     glob(os.path.join(image_folder, "*.png"))
        
        # Process in batches of 4
        batch_size = 4
        for i in range(0, len(image_files), batch_size):
            batch_files = image_files[i:i+batch_size]
            images = []
            labels = []
            
            for img_file in batch_files:
                img = Image.open(img_file).convert('RGB')
                img_tensor = transform(img)
                images.append(img_tensor)
                # Use filename as label (or 0 if unknown)
                labels.append(0)
            
            # Stack into batch
            if images:
                yield Batch(
                    inputs=torch.stack(images),
                    labels=torch.tensor(labels)
                )
    
    # Option 2: Use ImageNet validation set (if available)
    # Uncomment this if you have ImageNet dataset
    """
    imagenet_path = "/path/to/imagenet/val"
    if os.path.exists(imagenet_path):
        dataset = torchvision.datasets.ImageFolder(
            imagenet_path,
            transform=transform
        )
        dataloader = torch.utils.data.DataLoader(
            dataset, 
            batch_size=4, 
            shuffle=True
        )
        for images, labels in dataloader:
            yield Batch(inputs=images, labels=labels)
    """
    
    # Option 3: Use CIFAR-10 (works out of the box)
    dataset = torchvision.datasets.CIFAR10(
        root='./data',
        train=False,
        download=True,
        transform=transforms.Compose([
            transforms.Resize(224),  # Resize CIFAR to ResNet input size
            transforms.ToTensor()
        ])
    )
    
    dataloader = torch.utils.data.DataLoader(
        dataset,
        batch_size=4,
        shuffle=True
    )
    
    while True:  # Infinite iterator
        for images, labels in dataloader:
            yield Batch(inputs=images, labels=labels)

# ============================================
# STEP 5: Alternative - Load Specific Images
# ============================================

def load_specific_images(image_paths):
    """
    Load specific images for visualization
    
    Args:
        image_paths: List of paths to image files
    """
    transform = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor()
    ])
    
    def data_iter():
        batch_size = 4
        for i in range(0, len(image_paths), batch_size):
            batch_paths = image_paths[i:i+batch_size]
            images = []
            labels = []
            
            for img_path in batch_paths:
                img = Image.open(img_path).convert('RGB')
                img_tensor = transform(img)
                images.append(img_tensor)
                labels.append(0)  # Dummy label
            
            if images:
                yield Batch(
                    inputs=torch.stack(images),
                    labels=torch.tensor(labels)
                )
    
    return data_iter

# ============================================
# STEP 6: Initialize AttributionVisualizer
# ============================================

# Load model
model = get_pretrained_resnet()
print("Model loaded successfully!")

# Get class labels
classes = get_imagenet_classes()
print(f"Loaded {len(classes)} class labels")

# Define normalization (ImageNet normalization)
normalize = transforms.Normalize(
    mean=[0.485, 0.456, 0.406],
    std=[0.229, 0.224, 0.225]
)

# Create the visualizer
visualizer = AttributionVisualizer(
    models=[model],  # Can pass multiple models for comparison
    score_func=lambda output: F.softmax(output, dim=1),  # Convert logits to probabilities
    classes=classes,  # Class labels
    features=[
        ImageFeature(
            name="Image",  # Feature name
            baseline_transforms=[baseline_func],  # Baseline for attributions
            input_transforms=[normalize],  # Normalization applied before model
        )
    ],
    dataset=formatted_data_iter(),  # Data iterator
)

print("Visualizer initialized!")

# ============================================
# STEP 7: Launch the Visualizer
# ============================================

# Render in Jupyter Notebook
visualizer.render()

# This will display an interactive widget where you can:
# 1. Select different attribution methods (IntegratedGradients, Saliency, etc.)
# 2. Choose target classes
# 3. Adjust attribution parameters
# 4. View side-by-side comparisons
# 5. Filter predictions